# ---
# title: 3mm Stack-of-Spiral fMRI
# author: Pierre-Antoine Comby, Alexandre Vignaud, Philippe Ciuciu
# description: This is the configuration used for the scenario 2 of the SNAKE Paper
# ---

defaults:
  - base_config
  - handlers:
    - activation-block
  - sampler:
    - stacked-sequential-load-trajectory
  - reconstructors:
      # - adjoint
      #- sequential
      - cg
  - _self_

cache_dir: ${oc.env:PWD}/cache
result_dir: ${oc.env:PWD}/results/scenario2
filename:  ${result_dir}/scenario2_${engine.model}_${engine.snr}.mrd

sim_conf:
  max_sim_time: 4
  seq: {TR: 50, TE: 25,  FA: 12}
  hardware:
    n_coils: 1
    dwell_time_ms: 0.001
  fov:
    res_mm: [3.0, 3.0, 3.0]
    size: [182, 217, 120]
    offset: [-90,-125, -60]

phantom:
  name: brainweb
  sub_id: 5
  tissue_file: "tissue_7T"

handlers:
  activation-block:
    event_name: block_on
    block_on: 20 # seconds
    block_off: 20 #seconds
    duration: 300 # seconds
    delta_r2s: 1000 # millisecond^-1
#    atlas: "hardvard-oxford__cort-maxprob-thr0-1mm"
    atlas: "hardvard-oxford__cort-maxprob-thr50-1mm"
    atlas_label: 48

sampler:
  # stack-of-spiral:
  #   acsz: 0.1
  #   accelz: 4
  #   nb_revolutions: 12
  #   constant: true
  stacked-sequential-load-trajectory:
    path: "/volatile/Caini/stimulate/snake/notebook/bin_file_paths.txt"
    obs_time_ms: 30
    dwell_time: 0.001
    raster_time: 0.01
    accelz: 18
    acsz: 3
    constant: true
    constant_2d: true 


engine:
  n_jobs: 5
  chunk_size: 180
  model: "T2s"
  snr: 1000
  nufft_backend: "cufinufft"

reconstructors:
  # adjoint:
  #   nufft_backend: "stacked-gpunufft"
  #   density_compensation: "pipe"
  # sequential:
  #   density_compensation: false
  #   restart_strategy: COLD
  #   max_iter_per_frame: 50
  #   wavelet: "sym4"
  #   optimizer: "fista"
  cg:
    max_iter: 30
    tol: 1e-5
    restart_strategy: COLD





hydra:
  job:
    chdir: true

  run:
    dir: ${result_dir}/outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: ${result_dir}/multirun/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}

  callbacks:
    # gather_files:
    #   _target_: hydra_callbacks.MultiRunGatherer
    #   aggregator:
    #     _partial_: true
    #     _target_: snkf.cli.utils.aggregate_results

    log_job:
      _target_: hydra.experimental.callbacks.LogJobReturnCallback
    latest_run:
      _target_: hydra_callbacks.LatestRunLink
      run_base_dir:  ${result_dir}/outputs
      multirun_base_dir:  ${result_dir}/multirun
